{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conversational Movie Recommendations with RecBole and Gemini\n",
    "\n",
    "**Objective:** This notebook demonstrates how a pre-trained RecBole recommendation model can be used for inference to provide personalized movie recommendations within a simulated chatbot conversation powered by the Gemini API. The chatbot will also attempt to provide explanations for its recommendations based on the user's (simulated) viewing history.\n",
    "\n",
    "**Steps:**\n",
    "1.  **Setup & Configuration:** Import libraries, load API keys, configure SDKs, define paths, and set parameters (e.g., which RecBole model to load).\n",
    "2.  **Load MovieLens Item Data:** Load `u.item` to get movie titles and genres.\n",
    "3.  **Load Pre-trained RecBole Model & Dataset:** Load a saved model checkpoint and the corresponding dataset object from the previous RecBole evaluation notebook.\n",
    "4.  **Simulate User Profile & History:** Define a sample user and their liked movies.\n",
    "5.  **Generate Recommendations:** Use the loaded RecBole model to get recommendations for the simulated user.\n",
    "6.  **Conversational Agent (Gemini):**\n",
    "    a.  Define a function to interact with the Gemini API.\n",
    "    b.  Craft a prompt that takes the user's request, recommended movies (with genres), and liked movies (with genres) to generate a conversational response with explanations.\n",
    "7.  **Showcase Interaction:** Run an example chat interaction.\n",
    "\n",
    "**CRITICAL PREREQUISITES:**\n",
    "- Ensure libraries are installed:\n",
    "  `pip install recbole pandas python-dotenv google-generativeai`\n",
    "- A `.env` file in the project root with `GEMINI_API_KEY`.\n",
    "- A RecBole model checkpoint and dataset files saved from `04_recbole_offline_evaluation_v2.ipynb` in the `recbole_saved_models` and `recbole_data` directories respectively.\n",
    "- **The `u.item` file from the MovieLens 100k dataset MUST BE PRESENT in the `[PROJECT_ROOT]/recbole_data/ml-100k/` directory.**\n",
    "    - RecBole (in notebook `04`) should download and place this file here when it first processes the `ml-100k` dataset.\n",
    "    - **If `u.item` is NOT found at this location after running notebook `04` successfully, you MUST manually download the `ml-100k.zip` file from [https://grouplens.org/datasets/movielens/100k/](https://grouplens.org/datasets/movielens/100k/), extract it, and copy `u.item` (and preferably other `u.*` files) into your `[PROJECT_ROOT]/recbole_data/ml-100k/` directory.** This notebook cannot function without `u.item` for movie titles and genres.\n",
    "- **If the chosen RecBole model (e.g., LightGCN) required manual patches to its source code in the previous notebook, those patches must still be in effect in your RecBole installation for this notebook to work correctly.**\n"
   ],
   "id": "43b6c896a8e9ba60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T21:19:15.747149Z",
     "start_time": "2025-05-20T21:19:15.122122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import random\n",
    "import torch # Explicitly import torch for device checking if needed\n",
    "\n",
    "# For running async code in Jupyter environments smoothly\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Google Generative AI SDK\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# RecBole imports for loading model and data\n",
    "from recbole.quick_start import load_data_and_model\n",
    "# from recbole.utils.case_study import full_sort_scores, full_sort_topk # Not directly used, model.full_sort_predict is used\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "id": "5b6ef0d866c88c68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Define essential variables for API keys, paths, the RecBole model to load, and other parameters."
   ],
   "id": "779c0d8ee93a1110"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T21:20:01.818981Z",
     "start_time": "2025-05-20T21:20:01.529749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_api_key(project_r):\n",
    "    env_path = os.path.join(project_r, '.env')\n",
    "    if os.path.exists(env_path):\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        print(f\".env file loaded from: {env_path}\")\n",
    "    else:\n",
    "        load_dotenv()\n",
    "        if os.path.exists(\".env\"): print(f\".env file loaded from current directory: {os.getcwd()}/.env\")\n",
    "        else: print(f\"Warning: .env file not found at {env_path} or in current directory.\")\n",
    "    api_key_loaded = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key_loaded: print(\"Warning: GEMINI_API_KEY not found.\")\n",
    "    else: print(\"GEMINI_API_KEY loaded.\")\n",
    "    return api_key_loaded\n",
    "\n",
    "# --- Determine Project Root ---\n",
    "current_working_dir = os.getcwd()\n",
    "print(f\"Current working directory (os.getcwd()): {current_working_dir}\")\n",
    "if os.path.basename(current_working_dir).lower() == \"notebooks\":\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(current_working_dir, \"..\"))\n",
    "else:\n",
    "    PROJECT_ROOT = current_working_dir \n",
    "print(f\"PROJECT_ROOT set to: {PROJECT_ROOT}\")\n",
    "\n",
    "API_KEY = load_api_key(PROJECT_ROOT)\n",
    "\n",
    "# --- Configure Google Generative AI SDK ---\n",
    "SDK_CONFIGURED_SUCCESSFULLY = False\n",
    "if API_KEY: \n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        SDK_CONFIGURED_SUCCESSFULLY = True\n",
    "        print(\"Google Generative AI SDK configured successfully.\")\n",
    "    except Exception as e: print(f\"Error configuring Google Generative AI SDK: {e}\")\n",
    "else: print(\"Google Generative AI SDK not configured due to missing API key.\")\n",
    "\n",
    "# --- Directory and File Paths ---\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"recbole_data\")\n",
    "SAVED_MODELS_PATH = os.path.join(PROJECT_ROOT, \"recbole_saved_models\")\n",
    "ML_100K_RAW_PATH = os.path.join(DATA_PATH, \"ml-100k\") # Path where RecBole downloads ml-100k\n",
    "\n",
    "# --- Check for u.item (CRITICAL PREREQUISITE) ---\n",
    "U_ITEM_EXPECTED_PATH = os.path.join(ML_100K_RAW_PATH, 'u.item')\n",
    "if not os.path.exists(U_ITEM_EXPECTED_PATH):\n",
    "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(f\"CRITICAL ERROR: MovieLens item data file 'u.item' not found at: {U_ITEM_EXPECTED_PATH}\")\n",
    "    print(f\"This file is essential for mapping item IDs to titles and genres.\")\n",
    "    print(f\"It is typically downloaded by RecBole when you run notebook '04_recbole_offline_evaluation_v2.ipynb'.\")\n",
    "    print(f\"If it's missing, please MANUALLY download ml-100k.zip from https://grouplens.org/datasets/movielens/100k/,\")\n",
    "    print(f\"extract it, and copy 'u.item' into '{ML_100K_RAW_PATH}'.\")\n",
    "    print(f\"Stopping further execution in this cell as 'u.item' is missing.\")\n",
    "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    U_ITEM_FOUND = False\n",
    "else:\n",
    "    U_ITEM_FOUND = True\n",
    "    print(f\"'u.item' file found at: {U_ITEM_EXPECTED_PATH}\")\n",
    "\n",
    "\n",
    "# --- RecBole Model Loading Configuration ---\n",
    "MODEL_TO_LOAD = 'LightGCN' # The model type we intend to load\n",
    "\n",
    "# User-provided path for the specific model checkpoint\n",
    "USER_SPECIFIED_MODEL_SUBPATH = \"LightGCN_20250520_213658/LightGCN-May-20-2025_21-38-20.pth\"\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(SAVED_MODELS_PATH, \"ml-100k\", USER_SPECIFIED_MODEL_SUBPATH)\n",
    "\n",
    "print(f\"Attempting to load specified model checkpoint: {MODEL_CHECKPOINT_PATH}\")\n",
    "\n",
    "if not os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "    print(f\"CRITICAL: Specified model checkpoint file not found at '{MODEL_CHECKPOINT_PATH}'.\")\n",
    "    print(\"Please ensure the path is correct and the model file exists from the previous notebook's run.\")\n",
    "    # Fallback to auto-detection if user-specified path is not found (optional, can be removed if direct path is mandatory)\n",
    "    print(\"Attempting auto-detection as a fallback...\")\n",
    "    MODEL_CHECKPOINT_DIR_BASE = os.path.join(SAVED_MODELS_PATH, \"ml-100k\")\n",
    "    MODEL_CHECKPOINT_PATH = None # Reset for auto-detection\n",
    "    if os.path.exists(MODEL_CHECKPOINT_DIR_BASE):\n",
    "        model_dirs = [d for d in os.listdir(MODEL_CHECKPOINT_DIR_BASE) if os.path.isdir(os.path.join(MODEL_CHECKPOINT_DIR_BASE, d)) and d.startswith(MODEL_TO_LOAD)]\n",
    "        if model_dirs:\n",
    "            latest_model_dir_name = sorted(model_dirs, reverse=True)[0] \n",
    "            potential_model_dir = os.path.join(MODEL_CHECKPOINT_DIR_BASE, latest_model_dir_name)\n",
    "            pth_files = [f for f in os.listdir(potential_model_dir) if f.endswith(\".pth\")]\n",
    "            if pth_files:\n",
    "                MODEL_CHECKPOINT_PATH = os.path.join(potential_model_dir, pth_files[0])\n",
    "                print(f\"Auto-detected model checkpoint to load: {MODEL_CHECKPOINT_PATH}\")\n",
    "            else:\n",
    "                print(f\"Warning (auto-detection): No .pth file found in directory {potential_model_dir} for model {MODEL_TO_LOAD}.\")\n",
    "        else:\n",
    "            print(f\"Warning (auto-detection): No directories found starting with '{MODEL_TO_LOAD}' in {MODEL_CHECKPOINT_DIR_BASE}.\")\n",
    "    else:\n",
    "        print(f\"Warning (auto-detection): Base model checkpoint directory not found: {MODEL_CHECKPOINT_DIR_BASE}\")\n",
    "\n",
    "    if MODEL_CHECKPOINT_PATH is None:\n",
    "         print(f\"CRITICAL (auto-detection): Could not automatically find a checkpoint for model '{MODEL_TO_LOAD}'.\")\n",
    "\n",
    "# --- Other Parameters ---\n",
    "NUM_RECOMMENDATIONS = 5 # Number of movies to recommend\n",
    "\n",
    "print(f\"RecBole data path: {DATA_PATH}\")\n",
    "print(f\"MovieLens 100k raw path (expected for u.item): {ML_100K_RAW_PATH}\")"
   ],
   "id": "7b5d85c418d8ca39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory (os.getcwd()): /mnt/c/Users/tduricic/Development/workspace/conversational-reco/notebooks\n",
      "PROJECT_ROOT set to: /mnt/c/Users/tduricic/Development/workspace/conversational-reco\n",
      ".env file loaded from: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/.env\n",
      "GEMINI_API_KEY loaded.\n",
      "Google Generative AI SDK configured successfully.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "CRITICAL ERROR: MovieLens item data file 'u.item' not found at: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k/u.item\n",
      "This file is essential for mapping item IDs to titles and genres.\n",
      "It is typically downloaded by RecBole when you run notebook '04_recbole_offline_evaluation_v2.ipynb'.\n",
      "If it's missing, please MANUALLY download ml-100k.zip from https://grouplens.org/datasets/movielens/100k/,\n",
      "extract it, and copy 'u.item' into '/mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k'.\n",
      "Stopping further execution in this cell as 'u.item' is missing.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Attempting to load specified model checkpoint: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250520_213658/LightGCN-May-20-2025_21-38-20.pth\n",
      "RecBole data path: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data\n",
      "MovieLens 100k raw path (expected for u.item): /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Load MovieLens Item Data (Titles and Genres)\n",
    "\n",
    "We need to load the `u.item` file from the MovieLens 100k dataset to map item IDs to their actual titles and genres. This information is crucial for presenting recommendations to the user and for providing context to the LLM for generating explanations.\n",
    "This cell will only proceed if `u.item` was found in the previous cell."
   ],
   "id": "121661cfba32f216"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T20:29:35.811339Z",
     "start_time": "2025-05-20T20:29:34.412920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_movie_titles_and_genres(ml_100k_path):\n",
    "    \"\"\"Loads movie titles and genres from u.item.\"\"\"\n",
    "    u_item_file = os.path.join(ml_100k_path, 'u.item')\n",
    "    # The check for u_item_file existence is now primarily in CELL 4.\n",
    "    # This function assumes the path is valid if called.\n",
    "    if not os.path.exists(u_item_file): # Defensive check still good\n",
    "        print(f\"Error: u.item file not found at {u_item_file} (should have been caught earlier).\")\n",
    "        return None\n",
    "\n",
    "    item_cols = [\n",
    "        'movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url',\n",
    "        'genre_unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "        'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "        'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "    ]\n",
    "    try:\n",
    "        movies_df = pd.read_csv(u_item_file, sep='|', header=None, names=item_cols, encoding='latin-1')\n",
    "        \n",
    "        genre_columns = item_cols[5:] \n",
    "        def get_genres(row):\n",
    "            active_genres = [col for col in genre_columns if row[col] == 1]\n",
    "            return \", \".join(active_genres) if active_genres else \"N/A\"\n",
    "        \n",
    "        movies_df['genres_str'] = movies_df.apply(get_genres, axis=1)\n",
    "        \n",
    "        movie_info_map = movies_df.set_index('movie_id')[['movie_title', 'genres_str']].apply(\n",
    "            lambda x: {'title': x['movie_title'], 'genres': x['genres_str']}, axis=1\n",
    "        ).to_dict()\n",
    "        \n",
    "        print(f\"Loaded information for {len(movie_info_map)} movies from u.item.\")\n",
    "        return movie_info_map\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing u.item: {e}\")\n",
    "        return None\n",
    "\n",
    "movie_info_map = None\n",
    "if U_ITEM_FOUND: # Only attempt to load if the file was confirmed to exist\n",
    "    movie_info_map = load_movie_titles_and_genres(ML_100K_RAW_PATH)\n",
    "    if movie_info_map:\n",
    "        sample_movie_id = list(movie_info_map.keys())[0]\n",
    "        print(f\"\\nSample movie info (ID: {sample_movie_id}): {movie_info_map[sample_movie_id]}\")\n",
    "else:\n",
    "    print(\"\\nSkipping loading of u.item because the file was not found in the expected location.\")"
   ],
   "id": "a05e4df3dd743701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: u.item file not found at /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k/u.item\n",
      "Please ensure MovieLens 100k data is downloaded by RecBole or placed manually.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Load Pre-trained RecBole Model and Dataset\n",
    "\n",
    "This step loads the saved RecBole model checkpoint and its corresponding dataset object.\n",
    "The dataset object is essential as it contains the mappings between original user/item IDs and RecBole's internal numerical IDs.\n",
    "\n",
    "**Note:** This cell will fail if `MODEL_CHECKPOINT_PATH` is not correctly set or if the model/dataset files are missing.\n",
    "If the model (e.g., LightGCN) required manual patching of RecBole's source code to run correctly during training, those patches must still be in effect in your current RecBole installation.\n"
   ],
   "id": "a15260fd2f7cc34b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "recbole_model = None\n",
    "recbole_dataset = None\n",
    "\n",
    "if MODEL_CHECKPOINT_PATH and os.path.exists(MODEL_CHECKPOINT_PATH) and U_ITEM_FOUND: # Added U_ITEM_FOUND check\n",
    "    try:\n",
    "        print(f\"Loading RecBole model and dataset from checkpoint: {MODEL_CHECKPOINT_PATH}...\")\n",
    "        config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "            model_file=MODEL_CHECKPOINT_PATH,\n",
    "        )\n",
    "        recbole_model = model\n",
    "        recbole_dataset = dataset\n",
    "        print(f\"Successfully loaded model: {recbole_model.model_name}\")\n",
    "        print(f\"Dataset '{recbole_dataset.dataset_name}' loaded with {recbole_dataset.user_num} users and {recbole_dataset.item_num} items.\")\n",
    "        \n",
    "        recbole_model.eval()\n",
    "        recbole_model.to(torch.device('cpu')) \n",
    "        print(f\"Model '{recbole_model.model_name}' is on device: {next(recbole_model.parameters()).device}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RecBole model or dataset: {e}\")\n",
    "        print(\"Please ensure the MODEL_CHECKPOINT_PATH is correct and all necessary files (.pth, .dataset) are present.\")\n",
    "        print(\"Also, ensure your RecBole environment and any manual patches are consistent with the training environment.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "elif not U_ITEM_FOUND:\n",
    "    print(\"Skipping RecBole model loading because 'u.item' was not found (critical for movie info).\")\n",
    "else:\n",
    "    print(\"MODEL_CHECKPOINT_PATH is not set or file does not exist. Cannot load RecBole model.\")"
   ],
   "id": "2f574e54374c372f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Simulate User Profile & Generate Recommendations\n",
    "\n",
    "Here, we'll:\n",
    "1.  Define a sample user and a few movies they have \"liked\" (using movie titles).\n",
    "2.  Convert these liked movie titles into RecBole's internal item IDs.\n",
    "3.  Create an interaction object that RecBole can use for prediction.\n",
    "4.  Use the loaded RecBole model to generate top-N recommendations for this user.\n",
    "5.  Map the recommended internal item IDs back to movie titles and genres."
   ],
   "id": "f6b58b65fb36a706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_recommendations_for_user(model, dataset, user_original_id, user_liked_original_item_ids, top_k, movie_info):\n",
    "    \"\"\"\n",
    "    Generates top-K recommendations for a given user and their liked items.\n",
    "    \"\"\"\n",
    "    if model is None or dataset is None:\n",
    "        print(\"RecBole model or dataset not loaded. Cannot generate recommendations.\")\n",
    "        return [], []\n",
    "    if not movie_info: # Check if movie_info_map is available\n",
    "        print(\"Movie info (titles/genres) not loaded. Cannot provide full recommendation details.\")\n",
    "        return [], []\n",
    "\n",
    "\n",
    "    try:\n",
    "        internal_user_id_tensor = dataset.token2id(dataset.uid_field, [str(user_original_id)])\n",
    "        \n",
    "        if internal_user_id_tensor.size == 0 or internal_user_id_tensor[0] == 0: \n",
    "             print(f\"Warning: User ID '{user_original_id}' not found in dataset's known users or maps to unknown. Using first valid user.\")\n",
    "             first_original_uid = dataset.id2token(dataset.uid_field, [1])[0] \n",
    "             internal_user_id_tensor = dataset.token2id(dataset.uid_field, [first_original_uid])\n",
    "             print(f\"Using fallback user: original ID '{first_original_uid}', internal ID {internal_user_id_tensor[0]}\")\n",
    "\n",
    "        user_interaction = Interaction({dataset.uid_field: internal_user_id_tensor})\n",
    "        user_interaction = dataset.join(user_interaction) \n",
    "        user_interaction = user_interaction.to(model.device)\n",
    "\n",
    "        scores = model.full_sort_predict(user_interaction) \n",
    "\n",
    "        internal_liked_ids = []\n",
    "        if user_liked_original_item_ids:\n",
    "            internal_liked_ids_tensor = dataset.token2id(dataset.iid_field, [str(iid) for iid in user_liked_original_item_ids])\n",
    "            internal_liked_ids = [iid.item() for iid in internal_liked_ids_tensor if iid.item() != 0] \n",
    "\n",
    "        if internal_liked_ids:\n",
    "            valid_internal_liked_ids = [iid for iid in internal_liked_ids if iid < scores.shape[1]]\n",
    "            if valid_internal_liked_ids:\n",
    "                 scores[0, valid_internal_liked_ids] = -torch.inf \n",
    "\n",
    "        top_k_scores, top_k_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "        \n",
    "        recommended_internal_ids = top_k_indices.squeeze().tolist()\n",
    "        if not isinstance(recommended_internal_ids, list): # Handle single recommendation case\n",
    "            recommended_internal_ids = [recommended_internal_ids]\n",
    "        \n",
    "        recommended_movies_details = []\n",
    "        if movie_info: \n",
    "            original_item_ids_str = dataset.id2token(dataset.iid_field, recommended_internal_ids)\n",
    "            for original_id_str in original_item_ids_str:\n",
    "                try:\n",
    "                    original_id_int = int(original_id_str)\n",
    "                    info = movie_info.get(original_id_int)\n",
    "                    if info:\n",
    "                        recommended_movies_details.append({\n",
    "                            \"title\": info['title'],\n",
    "                            \"genres\": info['genres'],\n",
    "                            \"original_id\": original_id_int\n",
    "                        })\n",
    "                    else:\n",
    "                        recommended_movies_details.append({\n",
    "                            \"title\": f\"Unknown Movie (ID: {original_id_str})\",\n",
    "                            \"genres\": \"N/A\",\n",
    "                            \"original_id\": original_id_str\n",
    "                        })\n",
    "                except ValueError:\n",
    "                     recommended_movies_details.append({\n",
    "                            \"title\": f\"Unknown Movie (ID: {original_id_str} - non-integer)\",\n",
    "                            \"genres\": \"N/A\",\n",
    "                            \"original_id\": original_id_str\n",
    "                        })\n",
    "\n",
    "        liked_movies_details = []\n",
    "        if movie_info and user_liked_original_item_ids:\n",
    "            for original_id_str in user_liked_original_item_ids: # Iterate through the list of strings\n",
    "                try:\n",
    "                    original_id = int(original_id_str) # Convert to int for lookup\n",
    "                    info = movie_info.get(original_id) \n",
    "                    if info:\n",
    "                        liked_movies_details.append({\n",
    "                            \"title\": info['title'],\n",
    "                            \"genres\": info['genres'],\n",
    "                            \"original_id\": original_id\n",
    "                        })\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not convert liked movie ID '{original_id_str}' to integer.\")\n",
    "\n",
    "        \n",
    "        return recommended_movies_details, liked_movies_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return [], []\n",
    "\n",
    "# --- Simulate a User and their History ---\n",
    "SIMULATED_USER_ID = \"1\" \n",
    "SIMULATED_LIKED_MOVIE_ORIGINAL_IDS = [\"50\", \"100\", \"181\"] \n",
    "\n",
    "recommendations = [] # Initialize to ensure it exists\n",
    "liked_movie_details_for_prompt = [] # Initialize\n",
    "\n",
    "if recbole_model and recbole_dataset and movie_info_map: # Ensure movie_info_map is loaded\n",
    "    recommendations, liked_movie_details_for_prompt = get_recommendations_for_user(\n",
    "        recbole_model, \n",
    "        recbole_dataset, \n",
    "        SIMULATED_USER_ID, \n",
    "        SIMULATED_LIKED_MOVIE_ORIGINAL_IDS, \n",
    "        NUM_RECOMMENDATIONS,\n",
    "        movie_info_map\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Simulated User {SIMULATED_USER_ID} ---\")\n",
    "    print(\"Liked Movies (for prompt context):\")\n",
    "    if liked_movie_details_for_prompt:\n",
    "        for movie in liked_movie_details_for_prompt:\n",
    "            print(f\"- {movie['title']} (Genres: {movie['genres']})\")\n",
    "    else:\n",
    "        print(\"No liked movie details to display (movie_info_map might be missing or IDs not found).\")\n",
    "\n",
    "\n",
    "    print(\"\\nTop Recommendations:\")\n",
    "    if recommendations:\n",
    "        for i, movie in enumerate(recommendations):\n",
    "            print(f\"{i+1}. {movie['title']} (Genres: {movie['genres']})\")\n",
    "    else:\n",
    "        print(\"No recommendations generated or an error occurred.\")\n",
    "elif not movie_info_map:\n",
    "    print(\"Movie info (u.item) not loaded. Cannot proceed with user simulation and recommendations.\")\n",
    "else:\n",
    "    print(\"RecBole model/dataset not loaded. Skipping recommendation generation.\")"
   ],
   "id": "7a023b823dbe1fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Conversational Agent with Gemini\n",
    "\n",
    "This section defines a function to interact with the Gemini API. It will take the user's request, the generated movie recommendations (with titles and genres), and the user's liked movies (with titles and genres) to craft a conversational response that includes explanations."
   ],
   "id": "6d879fc9b815c806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def get_conversational_recommendation_with_explanation(user_query, recommended_movies, liked_movies_history):\n",
    "    if not SDK_CONFIGURED_SUCCESSFULLY:\n",
    "        return \"Sorry, I'm having trouble connecting to my brain right now. Please try again later.\"\n",
    "    if not recommended_movies:\n",
    "        return \"I couldn't find any specific recommendations for you right now, but I'm always learning! Perhaps try a broader query?\"\n",
    "\n",
    "    liked_movies_str = \"\"\n",
    "    if liked_movies_history:\n",
    "        liked_movies_parts = [f\"'{movie['title']}' (Genres: {movie['genres']})\" for movie in liked_movies_history]\n",
    "        if liked_movies_parts:\n",
    "            liked_movies_str = \"You previously liked: \" + \", \".join(liked_movies_parts) + \".\"\n",
    "\n",
    "    recs_str_parts = []\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        recs_str_parts.append(f\"{i+1}. '{movie['title']}' (Genres: {movie['genres']})\")\n",
    "    recs_str = \"\\n\".join(recs_str_parts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a friendly and helpful movie recommendation chatbot.\n",
    "    A user has asked: \"{user_query}\"\n",
    "    {liked_movies_str}\n",
    "\n",
    "    Here are some movie recommendations for the user:\n",
    "    {recs_str}\n",
    "\n",
    "    Your task is to:\n",
    "    1.  Present these recommendations in a conversational and engaging way.\n",
    "    2.  For each recommended movie, try to provide a brief, plausible explanation for why the user might like it, ideally by connecting it to their liked movies (considering titles and genres). For example, if they liked a sci-fi movie, and you recommend another sci-fi movie, mention that. If they liked a comedy, and you recommend another, highlight that.\n",
    "    3.  If you cannot find a strong direct link, provide a more general positive statement about the recommended movie.\n",
    "    4.  Keep the tone light and friendly. Do not invent movies or facts not provided.\n",
    "    5.  Structure your response as a single chat message.\n",
    "    \"\"\"\n",
    "\n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    "    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', safety_settings=safety_settings)\n",
    "    \n",
    "    try:\n",
    "        response = await model.generate_content_async(contents=[prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error interacting with Gemini API: {e}\")\n",
    "        return \"I'm sorry, I encountered an issue while trying to generate your recommendations with explanations. Please try again.\""
   ],
   "id": "c12d21002c76bd6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Showcase Chatbot Interaction\n",
    "\n",
    "Let's simulate a user asking for recommendations and see how our Gemini-powered chatbot responds, using the recommendations generated by the RecBole model.\n"
   ],
   "id": "e61530a0bae1eff2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def run_chatbot_example():\n",
    "    if not recommendations : # Check if recommendations list is populated and not empty\n",
    "        print(\"No recommendations available to run the chatbot example.\")\n",
    "        print(\"This might be due to errors in loading the RecBole model or generating recommendations.\")\n",
    "        return\n",
    "    if not liked_movie_details_for_prompt: # Also check liked movies for context\n",
    "        print(\"No liked movie details available for context in chatbot example.\")\n",
    "        # Optionally, decide if you want to proceed without liked movie context or stop\n",
    "        # For now, we'll let it proceed but the LLM won't have liked movies to refer to.\n",
    "\n",
    "    user_chat_query = \"Can you recommend some movies for me?\"\n",
    "    print(f\"\\nSimulated User Query: {user_chat_query}\")\n",
    "    \n",
    "    chatbot_response = await get_conversational_recommendation_with_explanation(\n",
    "        user_chat_query,\n",
    "        recommendations,\n",
    "        liked_movie_details_for_prompt \n",
    "    )\n",
    "    \n",
    "    print(\"\\nChatbot Response:\")\n",
    "    print(chatbot_response)\n",
    "\n",
    "if SDK_CONFIGURED_SUCCESSFULLY and recbole_model and recbole_dataset and movie_info_map and U_ITEM_FOUND:\n",
    "    if recommendations: # Ensure recommendations were actually generated\n",
    "        await run_chatbot_example() \n",
    "    else:\n",
    "        print(\"\\nSkipping chatbot example because no recommendations were generated (check previous steps).\")\n",
    "else:\n",
    "    print(\"\\nSkipping chatbot example because prerequisites (SDK, model, data, u.item, or initial recommendations) are missing.\")"
   ],
   "id": "2247d00beb160e2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Discussion on Explanation Quality and Further Improvements\n",
    "\n",
    "**Explanation Quality:**\n",
    "- The quality of explanations generated by the LLM heavily depends on:\n",
    "    - **Prompt Engineering:** How well the prompt guides the LLM to connect liked items with recommendations.\n",
    "    - **Available Information:** Providing genres (as we did) is helpful. More detailed item metadata (e.g., keywords, plot summaries, actors, directors) for both liked and recommended items would allow for richer and more accurate explanations.\n",
    "    - **LLM Capabilities:** The LLM's ability to infer relationships and articulate them naturally.\n",
    "- Simple genre-matching is a good starting point. More sophisticated explanations might require the LLM to understand deeper thematic connections or stylistic similarities.\n",
    "\n",
    "**Further Improvements:**\n",
    "1.  **Richer Item Metadata:** Incorporate more detailed movie metadata (plot keywords, director, main actors) into the prompt for both liked and recommended items to enable more nuanced explanations.\n",
    "2.  **User Feedback Loop:** In a real system, user feedback on recommendations and explanations could be used to fine-tune the LLM prompts or even the recommendation model.\n",
    "3.  **Multi-Turn Conversation:** Extend the chatbot to handle follow-up questions like \"Tell me more about 'Movie X'\" or \"Recommend something similar but less action-packed.\"\n",
    "4.  **Negative Feedback:** Allow users to say they disliked a recommendation, and use that to refine future suggestions and explanations.\n",
    "5.  **Diversity in Explanations:** Prompt the LLM to vary its explanation styles to avoid sounding repetitive.\n",
    "6.  **Knowledge Cutoff:** Be mindful of the LLM's knowledge cutoff if asking for information about very recent movies not in its training data (though here we provide the movie details directly).\n",
    "7.  **Fact-Checking (if LLM generates external info):** If the LLM were allowed to bring in external knowledge for explanations, a fact-checking layer might be needed. In our current setup, we are trying to constrain it to the provided data."
   ],
   "id": "b7580488a6410274"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def full_conversational_pipeline():\n",
    "    global synthetic_products_df, movie_info_map, recbole_model, recbole_dataset, recommendations, liked_movie_details_for_prompt, U_ITEM_FOUND\n",
    "\n",
    "    # Re-check U_ITEM_FOUND at the start of the pipeline\n",
    "    u_item_check_path = os.path.join(ML_100K_RAW_PATH, 'u.item')\n",
    "    U_ITEM_FOUND = os.path.exists(u_item_check_path)\n",
    "    if not U_ITEM_FOUND:\n",
    "        print(f\"CRITICAL (Pipeline Start): 'u.item' not found at {u_item_check_path}. Cannot proceed with conversational pipeline.\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Movie Info\n",
    "    movie_info_map = load_movie_titles_and_genres(ML_100K_RAW_PATH)\n",
    "    if not movie_info_map: return\n",
    "\n",
    "    # 2. Load RecBole Model\n",
    "    if MODEL_CHECKPOINT_PATH and os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "        try:\n",
    "            config, model, dataset, _, _, _ = load_data_and_model(model_file=MODEL_CHECKPOINT_PATH)\n",
    "            recbole_model = model\n",
    "            recbole_dataset = dataset\n",
    "            recbole_model.eval()\n",
    "            recbole_model.to(torch.device('cpu'))\n",
    "            print(f\"Successfully loaded model: {recbole_model.model_name} on device: {next(recbole_model.parameters()).device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading RecBole model in full pipeline: {e}\")\n",
    "            recbole_model, recbole_dataset = None, None \n",
    "            return \n",
    "    else:\n",
    "        print(\"Model checkpoint path not valid in full pipeline. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # 3. Simulate User and Get Recommendations\n",
    "    if recbole_model and recbole_dataset and movie_info_map:\n",
    "        recommendations, liked_movie_details_for_prompt = get_recommendations_for_user(\n",
    "            recbole_model, \n",
    "            recbole_dataset, \n",
    "            SIMULATED_USER_ID, \n",
    "            SIMULATED_LIKED_MOVIE_ORIGINAL_IDS, \n",
    "            NUM_RECOMMENDATIONS,\n",
    "            movie_info_map\n",
    "        )\n",
    "        print(f\"\\n--- Simulated User {SIMULATED_USER_ID} (Full Pipeline) ---\")\n",
    "        print(\"Liked Movies:\")\n",
    "        if liked_movie_details_for_prompt: \n",
    "            for movie in liked_movie_details_for_prompt: print(f\"- {movie['title']} (Genres: {movie['genres']})\")\n",
    "        else:\n",
    "            print(\"No liked movie details to display for prompt context.\")\n",
    "\n",
    "        print(\"\\nTop Recommendations:\")\n",
    "        if recommendations:\n",
    "            for i, movie in enumerate(recommendations): print(f\"{i+1}. {movie['title']} (Genres: {movie['genres']})\")\n",
    "        else:\n",
    "            print(\"No recommendations generated in full pipeline.\")\n",
    "    else:\n",
    "        print(\"Skipping recommendation generation in full pipeline due to missing components.\")\n",
    "        recommendations = [] \n",
    "        liked_movie_details_for_prompt = []\n",
    "\n",
    "\n",
    "    # 4. Run Chatbot Example\n",
    "    if SDK_CONFIGURED_SUCCESSFULLY and recommendations: \n",
    "        await run_chatbot_example()\n",
    "    else:\n",
    "        print(\"\\nSkipping chatbot example in full pipeline due to missing SDK config or recommendations.\")"
   ],
   "id": "5ee169e402b85ba4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "await full_conversational_pipeline()",
   "id": "1b83836a793c4147"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
