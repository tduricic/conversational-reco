{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b6c896a8e9ba60",
   "metadata": {},
   "source": [
    "# Conversational Movie Recommendations with RecBole and Gemini\n",
    "\n",
    "**Objective:** This notebook demonstrates how a pre-trained RecBole recommendation model can be used for inference to provide personalized movie recommendations within a simulated chatbot conversation powered by the Gemini API. The chatbot will also attempt to provide explanations for its recommendations based on the user's (simulated) viewing history.\n",
    "\n",
    "**Steps:**\n",
    "1.  **Setup & Configuration:** Import libraries, load API keys, configure SDKs, define paths, and set parameters.\n",
    "2.  **Load MovieLens Item Data:** Load movie titles and genres from RecBole's processed `ml-100k.item` file.\n",
    "3.  **Load Pre-trained RecBole Model & Dataset:** Load a saved model checkpoint and the corresponding dataset object.\n",
    "4.  **Simulate User Profile & History:** Define a sample user and their liked movies (using original MovieLens IDs).\n",
    "5.  **Generate Recommendations:** Use the loaded RecBole model to get recommendations.\n",
    "6.  **Conversational Agent (Gemini):** Craft prompts and interact with Gemini for conversational output.\n",
    "7.  **Showcase Interaction:** Run an example chat.\n",
    "\n",
    "**CRITICAL PREREQUISITES:**\n",
    "- Ensure libraries are installed:\n",
    "  `pip install recbole pandas python-dotenv google-generativeai`\n",
    "- A `.env` file in the project root with `GEMINI_API_KEY`.\n",
    "- A RecBole model checkpoint saved from `04_recbole_offline_evaluation_v2.ipynb`.\n",
    "- **RecBole's processed atomic files (e.g., `ml-100k.item`, `ml-100k.dataset`) MUST BE PRESENT in the `[PROJECT_ROOT]/recbole_data/ml-100k/` directory.** These are generated by notebook `04` when `save_dataset: True` is set.\n",
    "- **If the chosen RecBole model required manual patches to its source code in notebook `04`, those patches must still be in effect.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b6ef0d866c88c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:34.245669Z",
     "start_time": "2025-05-21T22:02:07.191344Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import random\n",
    "import torch \n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.data.dataset import Dataset # For type hinting if needed\n",
    "\n",
    "# For interactive chat widget\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "779c0d8ee93a1110",
   "metadata": {},
   "source": [
    "# 2. Configuration\n",
    "Define essential variables."
   ]
  },
  {
   "cell_type": "code",
   "id": "7b5d85c418d8ca39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:36.115899Z",
     "start_time": "2025-05-21T22:02:34.248705Z"
    }
   },
   "source": [
    "def load_api_key(project_r):\n",
    "    env_path = os.path.join(project_r, '.env')\n",
    "    if os.path.exists(env_path):\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        print(f\".env file loaded from: {env_path}\")\n",
    "    else:\n",
    "        load_dotenv()\n",
    "        if os.path.exists(\".env\"): print(f\".env file loaded from current directory: {os.getcwd()}/.env\")\n",
    "        else: print(f\"Warning: .env file not found at {env_path} or in current directory.\")\n",
    "    api_key_loaded = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key_loaded: print(\"Warning: GEMINI_API_KEY not found.\")\n",
    "    else: print(\"GEMINI_API_KEY loaded.\")\n",
    "    return api_key_loaded\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "print(f\"Current working directory (os.getcwd()): {current_working_dir}\")\n",
    "if os.path.basename(current_working_dir).lower() == \"notebooks\":\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(current_working_dir, \"..\"))\n",
    "else:\n",
    "    PROJECT_ROOT = current_working_dir \n",
    "print(f\"PROJECT_ROOT set to: {PROJECT_ROOT}\")\n",
    "\n",
    "API_KEY = load_api_key(PROJECT_ROOT)\n",
    "\n",
    "SDK_CONFIGURED_SUCCESSFULLY = False\n",
    "if API_KEY: \n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        SDK_CONFIGURED_SUCCESSFULLY = True\n",
    "        print(\"Google Generative AI SDK configured successfully.\")\n",
    "    except Exception as e: print(f\"Error configuring Google Generative AI SDK: {e}\")\n",
    "else: print(\"Google Generative AI SDK not configured due to missing API key.\")\n",
    "\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"recbole_data\")\n",
    "SAVED_MODELS_PATH = os.path.join(PROJECT_ROOT, \"recbole_saved_models\")\n",
    "# This path should point to the directory containing ml-100k.item, ml-100k.inter etc.\n",
    "ML_100K_PROCESSED_PATH = os.path.join(DATA_PATH, \"ml-100k\") \n",
    "\n",
    "RECDOBOLE_ITEM_FILE_NAME = \"ml-100k.item\" # RecBole's processed item file\n",
    "RECDOBOLE_ITEM_FILE_PATH = os.path.join(ML_100K_PROCESSED_PATH, RECDOBOLE_ITEM_FILE_NAME)\n",
    "\n",
    "if not os.path.exists(RECDOBOLE_ITEM_FILE_PATH):\n",
    "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(f\"CRITICAL ERROR: RecBole's processed item file '{RECDOBOLE_ITEM_FILE_NAME}' not found at: {RECDOBOLE_ITEM_FILE_PATH}\")\n",
    "    print(f\"This file is essential for mapping item IDs to titles and genres.\")\n",
    "    print(f\"It is generated by RecBole when you run notebook '04_recbole_offline_evaluation_v2.ipynb' with 'save_dataset: True'.\")\n",
    "    print(f\"Please ensure that notebook ran successfully and created the processed dataset files in '{ML_100K_PROCESSED_PATH}'.\")\n",
    "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    PROCESSED_ITEM_FILE_FOUND = False\n",
    "else:\n",
    "    PROCESSED_ITEM_FILE_FOUND = True\n",
    "    print(f\"RecBole's processed item file '{RECDOBOLE_ITEM_FILE_NAME}' found at: {RECDOBOLE_ITEM_FILE_PATH}\")\n",
    "\n",
    "MODEL_TO_LOAD = 'LightGCN'\n",
    "USER_SPECIFIED_MODEL_SUBPATH = \"LightGCN_20250520_213658/LightGCN-May-20-2025_21-38-20.pth\" # User provided\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(SAVED_MODELS_PATH, \"ml-100k\", USER_SPECIFIED_MODEL_SUBPATH)\n",
    "\n",
    "print(f\"Attempting to load specified model checkpoint: {MODEL_CHECKPOINT_PATH}\")\n",
    "if not os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "     print(f\"CRITICAL: Specified model checkpoint file not found at '{MODEL_CHECKPOINT_PATH}'. Auto-detection will be attempted if enabled.\")\n",
    "     # Auto-detection fallback logic (can be kept or removed if direct path is mandatory)\n",
    "     MODEL_CHECKPOINT_DIR_BASE = os.path.join(SAVED_MODELS_PATH, \"ml-100k\")\n",
    "     MODEL_CHECKPOINT_PATH_AUTO = None \n",
    "     if os.path.exists(MODEL_CHECKPOINT_DIR_BASE):\n",
    "        model_dirs = [d for d in os.listdir(MODEL_CHECKPOINT_DIR_BASE) if os.path.isdir(os.path.join(MODEL_CHECKPOINT_DIR_BASE, d)) and d.startswith(MODEL_TO_LOAD)]\n",
    "        if model_dirs:\n",
    "            latest_model_dir_name = sorted(model_dirs, reverse=True)[0] \n",
    "            potential_model_dir = os.path.join(MODEL_CHECKPOINT_DIR_BASE, latest_model_dir_name)\n",
    "            pth_files = [f for f in os.listdir(potential_model_dir) if f.endswith(\".pth\")]\n",
    "            if pth_files:\n",
    "                MODEL_CHECKPOINT_PATH_AUTO = os.path.join(potential_model_dir, pth_files[0])\n",
    "                print(f\"Auto-detected model checkpoint to load: {MODEL_CHECKPOINT_PATH_AUTO}\")\n",
    "                MODEL_CHECKPOINT_PATH = MODEL_CHECKPOINT_PATH_AUTO \n",
    "            else: print(f\"Warning (auto-detection): No .pth file found in {potential_model_dir} for {MODEL_TO_LOAD}.\")\n",
    "        else: print(f\"Warning (auto-detection): No directories for '{MODEL_TO_LOAD}' in {MODEL_CHECKPOINT_DIR_BASE}.\")\n",
    "     else: print(f\"Warning (auto-detection): Base model checkpoint directory not found: {MODEL_CHECKPOINT_DIR_BASE}\")\n",
    "     if MODEL_CHECKPOINT_PATH is None or not os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "         print(f\"CRITICAL: Could not find a valid checkpoint for model '{MODEL_TO_LOAD}'.\")\n",
    "         MODEL_CHECKPOINT_PATH = None\n",
    "\n",
    "NUM_RECOMMENDATIONS = 5\n",
    "print(f\"RecBole processed data path (expected): {ML_100K_PROCESSED_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory (os.getcwd()): /mnt/c/Users/tduricic/Development/workspace/conversational-reco/notebooks\n",
      "PROJECT_ROOT set to: /mnt/c/Users/tduricic/Development/workspace/conversational-reco\n",
      ".env file loaded from: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/.env\n",
      "GEMINI_API_KEY loaded.\n",
      "Google Generative AI SDK configured successfully.\n",
      "RecBole's processed item file 'ml-100k.item' found at: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k/ml-100k.item\n",
      "Attempting to load specified model checkpoint: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250520_213658/LightGCN-May-20-2025_21-38-20.pth\n",
      "CRITICAL: Specified model checkpoint file not found at '/mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250520_213658/LightGCN-May-20-2025_21-38-20.pth'. Auto-detection will be attempted if enabled.\n",
      "Auto-detected model checkpoint to load: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428/LightGCN-May-21-2025_20-36-30.pth\n",
      "RecBole processed data path (expected): /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_data/ml-100k\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "121661cfba32f216",
   "metadata": {},
   "source": [
    "## 3. Load MovieLens Item Data (Titles and Genres) from RecBole's Processed File\n",
    "\n",
    "We will load movie titles and genres from RecBole's processed `ml-100k.item` file.\n",
    "This file contains item IDs (RecBole's internal integer IDs), movie titles (as token sequences),\n",
    "and classes/genres (as token sequences)."
   ]
  },
  {
   "cell_type": "code",
   "id": "a05e4df3dd743701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:37.986086Z",
     "start_time": "2025-05-21T22:02:36.120017Z"
    }
   },
   "source": [
    "def load_recbole_item_data(processed_item_file_path):\n",
    "    \"\"\"Loads movie titles and genres from RecBole's .item file.\"\"\"\n",
    "    if not os.path.exists(processed_item_file_path):\n",
    "        print(f\"Error: RecBole processed item file not found at {processed_item_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    movie_info_map_internal_id = {}\n",
    "    try:\n",
    "        with open(processed_item_file_path, 'r', encoding='utf-8') as f:\n",
    "            header_line = f.readline().strip()\n",
    "            header_parts = header_line.split('\\t')\n",
    "            if len(header_parts) < 3: \n",
    "                 header_parts = [h.strip() for h in header_line.split(' ') if h.strip()]\n",
    "\n",
    "            try:\n",
    "                item_id_col_name = next(col for col in header_parts if 'item_id:token' in col)\n",
    "                title_col_name = next(col for col in header_parts if 'movie_title:token_seq' in col)\n",
    "                class_col_name = next(col for col in header_parts if 'class:token_seq' in col)\n",
    "                \n",
    "                item_id_idx = header_parts.index(item_id_col_name)\n",
    "                title_idx = header_parts.index(title_col_name)\n",
    "                class_idx = header_parts.index(class_col_name)\n",
    "            except (StopIteration, ValueError) as ve:\n",
    "                print(f\"Header parsing error in {processed_item_file_path}. Expected specific column field names (e.g., 'item_id:token'). Header found: {header_parts}. Error: {ve}\")\n",
    "                return None\n",
    "\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) < max(item_id_idx, title_idx, class_idx) + 1:\n",
    "                    parts = [p.strip() for p in line.strip().split(' ') if p.strip()]\n",
    "                    if len(parts) < max(item_id_idx, title_idx, class_idx) + 1:\n",
    "                        continue\n",
    "                \n",
    "                try:\n",
    "                    internal_item_id = int(parts[item_id_idx]) \n",
    "                    \n",
    "                    year_token = \"UNKNOWN_YEAR\" \n",
    "                    title_tokens_list = []\n",
    "                    class_tokens_list = []\n",
    "                    potential_year_idx = -1\n",
    "                    temp_title_parts = []\n",
    "                    # Corrected logic: iterate from title_idx up to the end of parts to find year\n",
    "                    # then class tokens are after year, title tokens are before year.\n",
    "                    \n",
    "                    # Find year first\n",
    "                    for i in range(title_idx, len(parts)):\n",
    "                        token = parts[i]\n",
    "                        if len(token) == 4 and token.isdigit() and 1880 <= int(token) <= 2050:\n",
    "                            potential_year_idx = i\n",
    "                            year_token = token\n",
    "                            break\n",
    "                    \n",
    "                    if potential_year_idx != -1: # Year was found\n",
    "                        title_tokens_list = parts[title_idx:potential_year_idx]\n",
    "                        class_tokens_list = parts[potential_year_idx + 1:]\n",
    "                    else: # No year found, assume title is up to class_idx, and class is from class_idx\n",
    "                          # This might happen if year is missing or class_idx is not reliable for separation\n",
    "                        title_tokens_list = parts[title_idx:class_idx] # If class_idx is the start of class tokens\n",
    "                        class_tokens_list = parts[class_idx:]\n",
    "\n",
    "\n",
    "                    movie_title = \" \".join(title_tokens_list).strip()\n",
    "                    genres_str = \" \".join(class_tokens_list).strip()\n",
    "                    if not movie_title: movie_title = f\"Unknown Title (ID: {internal_item_id})\"\n",
    "                    if not genres_str: genres_str = \"N/A\"\n",
    "                    \n",
    "                    movie_info_map_internal_id[internal_item_id] = {\n",
    "                        'title': movie_title,\n",
    "                        'genres': genres_str\n",
    "                    }\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"Skipping line {line_num} due to parsing error: '{line.strip()}'. Error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Loaded information for {len(movie_info_map_internal_id)} movies from RecBole's .item file.\")\n",
    "        return movie_info_map_internal_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing RecBole's .item file {processed_item_file_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "movie_info_map = None\n",
    "if PROCESSED_ITEM_FILE_FOUND:\n",
    "    movie_info_map = load_recbole_item_data(RECDOBOLE_ITEM_FILE_PATH)\n",
    "    if movie_info_map:\n",
    "        if movie_info_map: \n",
    "            valid_keys = [k for k in movie_info_map.keys() if isinstance(k, int) and k > 0]\n",
    "            if valid_keys:\n",
    "                sample_internal_item_id = valid_keys[0]\n",
    "                print(f\"\\nSample movie info (Internal ID: {sample_internal_item_id}): {movie_info_map[sample_internal_item_id]}\")\n",
    "            else:\n",
    "                print(\"\\nNo valid integer keys found in movie_info_map for sample display.\")\n",
    "        else:\n",
    "            print(\"\\nMovie info map is empty after loading RecBole's .item file.\")\n",
    "else:\n",
    "    print(\"\\nSkipping loading of RecBole's .item file because it was not found.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded information for 1682 movies from RecBole's .item file.\n",
      "\n",
      "Sample movie info (Internal ID: 1): {'title': 'Toy Story', 'genres': \"Animation Children's Comedy\"}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a15260fd2f7cc34b",
   "metadata": {},
   "source": [
    "## 4. Load Pre-trained RecBole Model and Dataset\n",
    "\n",
    "This step loads the saved RecBole model checkpoint and its corresponding dataset object.\n",
    "The dataset object is essential as it contains the mappings between original user/item IDs and RecBole's internal numerical IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f574e54374c372f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:43.596255Z",
     "start_time": "2025-05-21T22:02:37.993738Z"
    }
   },
   "source": [
    "recbole_model = None\n",
    "recbole_dataset = None\n",
    "recbole_config = None # To store the config object from loading\n",
    "\n",
    "if MODEL_CHECKPOINT_PATH and os.path.exists(MODEL_CHECKPOINT_PATH) and PROCESSED_ITEM_FILE_FOUND:\n",
    "    try:\n",
    "        print(f\"Loading RecBole model and dataset from checkpoint: {MODEL_CHECKPOINT_PATH}...\")\n",
    "        loaded_config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "            model_file=MODEL_CHECKPOINT_PATH,\n",
    "        )\n",
    "        recbole_model = model\n",
    "        recbole_dataset = dataset\n",
    "        recbole_config = loaded_config \n",
    "        \n",
    "        print(f\"Successfully loaded model: {recbole_config['model']}\") \n",
    "        print(f\"Dataset '{recbole_dataset.dataset_name}' loaded with {recbole_dataset.user_num} users and {recbole_dataset.item_num} items.\")\n",
    "        \n",
    "        recbole_model.eval()\n",
    "        recbole_model.to(torch.device('cpu')) \n",
    "        print(f\"Model '{recbole_config['model']}' is on device: {next(recbole_model.parameters()).device}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RecBole model or dataset: {e}\")\n",
    "        print(\"Please ensure the MODEL_CHECKPOINT_PATH is correct and all necessary files (.pth, .dataset) are present.\")\n",
    "        print(\"Also, ensure your RecBole environment and any manual patches are consistent with the training environment.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "elif not PROCESSED_ITEM_FILE_FOUND:\n",
    "    print(\"Skipping RecBole model loading because RecBole's processed .item file was not found.\")\n",
    "else:\n",
    "    print(\"MODEL_CHECKPOINT_PATH is not set or file does not exist. Cannot load RecBole model.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tduricic/anaconda3/envs/llm-eval/lib/python3.10/site-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_file)\n",
      "22 May 00:02    INFO  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RecBole model and dataset from checkpoint: /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428/LightGCN-May-21-2025_20-36-30.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "General Hyper Parameters:\n",
      "gpu_id = -1\n",
      "use_gpu = True\n",
      "seed = 2024\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /home/tduricic/anaconda3/envs/llm-eval/lib/python3.10/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'Precision', 'NDCG', 'MRR', 'ItemCoverage', 'GiniIndex', 'ShannonEntropy', 'AveragePopularity', 'TailPercentage']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 2048\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 3}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "n_layers = 2\n",
      "reg_weight = 1e-05\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "reproducible = True\n",
      "download_original_data = True\n",
      "eval_setting = RO_RS,full\n",
      "split_ratio = [0.8, 0.1, 0.1]\n",
      "leave_one_out = False\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "22 May 00:02    INFO  Load filtered dataset from: [/mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428/ml-100k-Dataset.pth]\n",
      "22 May 00:02    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'label']\n",
      "22 May 00:02    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "22 May 00:02    INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "/home/tduricic/anaconda3/envs/llm-eval/lib/python3.10/site-packages/recbole/model/general_recommender/lightgcn.py:127: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
      "  SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model: LightGCN\n",
      "Dataset 'ml-100k' loaded with 944 users and 1683 items.\n",
      "Model 'LightGCN' is on device: cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f6b58b65fb36a706",
   "metadata": {},
   "source": [
    "## 5. Simulate User Profile & Generate Recommendations\n",
    "\n",
    "Here, we'll:\n",
    "1.  Define a sample user and a few movies they have \"liked\" (using their original MovieLens string IDs).\n",
    "2.  Convert these original string IDs into RecBole's internal integer item IDs for filtering.\n",
    "3.  Use the loaded RecBole model to generate top-N recommendations (internal integer IDs).\n",
    "4.  Map the recommended internal integer item IDs and the liked internal integer item IDs back to movie titles and genres using our `movie_info_map` (which is keyed by internal integer IDs).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a023b823dbe1fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:45.476104Z",
     "start_time": "2025-05-21T22:02:43.599810Z"
    }
   },
   "source": [
    "def get_user_history_details(dataset: 'Dataset', user_original_id_str: str, internal_id_movie_info_map: dict, rating_threshold:float=3.0):\n",
    "    \"\"\"Fetches and formats the interaction history for a given user.\"\"\"\n",
    "    if not dataset or not internal_id_movie_info_map:\n",
    "        print(\"Dataset or movie_info_map not available for get_user_history_details.\")\n",
    "        return []\n",
    "    \n",
    "    history_details = []\n",
    "    try:\n",
    "        internal_uid_np = dataset.token2id(dataset.uid_field, [user_original_id_str])\n",
    "        \n",
    "        uid_padding_token = 0 \n",
    "        if hasattr(dataset.config, 'padding_idx') and isinstance(dataset.config['padding_idx'], dict) and dataset.uid_field in dataset.config['padding_idx']:\n",
    "             uid_padding_token = dataset.config['padding_idx'][dataset.uid_field]\n",
    "        elif hasattr(dataset, 'padding_token') and isinstance(dataset.padding_token, dict) and dataset.uid_field in dataset.padding_token: \n",
    "             uid_padding_token = dataset.padding_token[dataset.uid_field]\n",
    "\n",
    "        if internal_uid_np.size == 0 or internal_uid_np[0] == uid_padding_token: \n",
    "            print(f\"User {user_original_id_str} not found in dataset or maps to padding token for history lookup.\")\n",
    "            return []\n",
    "        internal_uid = internal_uid_np[0]\n",
    "\n",
    "        # Convert Interaction object's data to a Pandas DataFrame\n",
    "        # The .interaction attribute holds the dictionary of tensors\n",
    "        interaction_data_dict = {\n",
    "            field: tensor.cpu().numpy() \n",
    "            for field, tensor in dataset.inter_feat.interaction.items()\n",
    "        }\n",
    "        all_interactions_df = pd.DataFrame(interaction_data_dict)\n",
    "        \n",
    "        # Filter for the specific user\n",
    "        user_interactions_df = all_interactions_df[all_interactions_df[dataset.uid_field] == internal_uid].copy()\n",
    "        \n",
    "        rating_field_name = dataset.config['RATING_FIELD']\n",
    "        time_field_name = dataset.config['TIME_FIELD']\n",
    "        item_id_field_name = dataset.config['ITEM_ID_FIELD']\n",
    "\n",
    "        if rating_field_name and rating_field_name in user_interactions_df.columns:\n",
    "            user_interactions_df[rating_field_name] = pd.to_numeric(user_interactions_df[rating_field_name], errors='coerce')\n",
    "            user_interactions_df = user_interactions_df[user_interactions_df[rating_field_name] >= rating_threshold]\n",
    "        \n",
    "        if time_field_name and time_field_name in user_interactions_df.columns:\n",
    "            user_interactions_df = user_interactions_df.sort_values(by=time_field_name, ascending=False)\n",
    "\n",
    "        for _, interaction in user_interactions_df.iterrows():\n",
    "            internal_item_id = int(interaction[item_id_field_name])\n",
    "            movie_detail = internal_id_movie_info_map.get(internal_item_id)\n",
    "            if movie_detail:\n",
    "                rating_value = \"N/A\"\n",
    "                if rating_field_name and rating_field_name in interaction:\n",
    "                    rating_value = interaction[rating_field_name]\n",
    "                history_details.append({\n",
    "                    \"title\": movie_detail['title'],\n",
    "                    \"genres\": movie_detail['genres'],\n",
    "                    \"rating\": rating_value\n",
    "                })\n",
    "        return history_details\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching user history for {user_original_id_str}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_recommendations_for_user(model, dataset: 'Dataset', user_original_id_str, user_liked_original_item_ids_str_list, top_k, internal_id_movie_info_map):\n",
    "    if model is None or dataset is None:\n",
    "        print(\"RecBole model or dataset not loaded. Cannot generate recommendations.\")\n",
    "        return [], []\n",
    "    if not internal_id_movie_info_map:\n",
    "        print(\"Movie info (from .item file) not loaded. Cannot provide full recommendation details.\")\n",
    "        return [], []\n",
    "\n",
    "    try:\n",
    "        internal_user_id_np_array = dataset.token2id(dataset.uid_field, [str(user_original_id_str)])\n",
    "        \n",
    "        uid_padding_token = 0 \n",
    "        if hasattr(dataset.config, 'padding_idx') and isinstance(dataset.config['padding_idx'], dict) and dataset.uid_field in dataset.config['padding_idx']:\n",
    "            uid_padding_token = dataset.config['padding_idx'][dataset.uid_field]\n",
    "        elif hasattr(dataset, 'padding_token') and isinstance(dataset.padding_token, dict) and dataset.uid_field in dataset.padding_token: \n",
    "             uid_padding_token = dataset.padding_token[dataset.uid_field]\n",
    "\n",
    "\n",
    "        if internal_user_id_np_array.size == 0 or internal_user_id_np_array[0] == uid_padding_token: \n",
    "             print(f\"Warning: User ID '{user_original_id_str}' not found or maps to padding token ({uid_padding_token}). Using first valid user from dataset.\")\n",
    "             first_valid_original_uid_str = dataset.id2token(dataset.uid_field, [1])[0] \n",
    "             internal_user_id_np_array = dataset.token2id(dataset.uid_field, [first_valid_original_uid_str])\n",
    "             print(f\"Using fallback user: original ID '{first_valid_original_uid_str}', internal ID {internal_user_id_np_array[0]}\")\n",
    "        \n",
    "        internal_user_id_tensor = torch.tensor(internal_user_id_np_array, dtype=torch.long, device=model.device)\n",
    "\n",
    "        user_interaction = Interaction({dataset.uid_field: internal_user_id_tensor})\n",
    "        user_interaction = dataset.join(user_interaction) \n",
    "        user_interaction = user_interaction.to(model.device)\n",
    "\n",
    "        scores = model.full_sort_predict(user_interaction) \n",
    "\n",
    "        if scores.dim() == 1:\n",
    "            scores = scores.unsqueeze(0) \n",
    "\n",
    "        internal_liked_ids_int_list = []\n",
    "        if user_liked_original_item_ids_str_list:\n",
    "            internal_liked_ids_np_array = dataset.token2id(dataset.iid_field, [str(iid) for iid in user_liked_original_item_ids_str_list])\n",
    "            iid_padding_token = 0 \n",
    "            if hasattr(dataset.config, 'padding_idx') and isinstance(dataset.config['padding_idx'], dict) and dataset.iid_field in dataset.config['padding_idx']:\n",
    "                 iid_padding_token = dataset.config['padding_idx'][dataset.iid_field]\n",
    "            elif hasattr(dataset, 'padding_token') and isinstance(dataset.padding_token, dict) and dataset.iid_field in dataset.padding_token:\n",
    "                 iid_padding_token = dataset.padding_token[dataset.iid_field]\n",
    "            internal_liked_ids_int_list = [int(iid) for iid in internal_liked_ids_np_array if iid != iid_padding_token and iid < dataset.item_num] \n",
    "\n",
    "        if internal_liked_ids_int_list:\n",
    "            valid_internal_liked_ids = [iid for iid in internal_liked_ids_int_list if iid < scores.shape[1]]\n",
    "            if valid_internal_liked_ids:\n",
    "                 liked_ids_tensor = torch.tensor(valid_internal_liked_ids, dtype=torch.long, device=scores.device)\n",
    "                 scores[0, liked_ids_tensor] = -torch.inf\n",
    "        \n",
    "        top_k_scores, top_k_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "        \n",
    "        recommended_internal_ids_int_list = top_k_indices.squeeze().tolist()\n",
    "        if not isinstance(recommended_internal_ids_int_list, list): \n",
    "            recommended_internal_ids_int_list = [recommended_internal_ids_int_list]\n",
    "        \n",
    "        recommended_movies_details = []\n",
    "        for internal_id_int in recommended_internal_ids_int_list:\n",
    "            info = internal_id_movie_info_map.get(internal_id_int)\n",
    "            if info:\n",
    "                recommended_movies_details.append({\n",
    "                    \"title\": info['title'], \"genres\": info['genres'], \n",
    "                    \"internal_id\": internal_id_int \n",
    "                })\n",
    "            else:\n",
    "                 recommended_movies_details.append({\n",
    "                    \"title\": f\"Unknown Movie (Internal ID: {internal_id_int})\", \"genres\": \"N/A\", \n",
    "                    \"internal_id\": internal_id_int\n",
    "                })\n",
    "        \n",
    "        liked_movies_details = []\n",
    "        if user_liked_original_item_ids_str_list:\n",
    "            internal_liked_ids_for_prompt_np = dataset.token2id(dataset.iid_field, [str(iid) for iid in user_liked_original_item_ids_str_list])\n",
    "            iid_padding_token = 0\n",
    "            if hasattr(dataset.config, 'padding_idx') and isinstance(dataset.config['padding_idx'], dict) and dataset.iid_field in dataset.config['padding_idx']:\n",
    "                 iid_padding_token = dataset.config['padding_idx'][dataset.iid_field]\n",
    "            elif hasattr(dataset, 'padding_token') and isinstance(dataset.padding_token, dict) and dataset.iid_field in dataset.padding_token:\n",
    "                 iid_padding_token = dataset.padding_token[dataset.iid_field]\n",
    "\n",
    "            for internal_id_int_np in internal_liked_ids_for_prompt_np:\n",
    "                internal_id_int = int(internal_id_int_np) \n",
    "                if internal_id_int == iid_padding_token or internal_id_int >= dataset.item_num:\n",
    "                    continue \n",
    "                info = internal_id_movie_info_map.get(internal_id_int)\n",
    "                if info:\n",
    "                    liked_movies_details.append({\n",
    "                        \"title\": info['title'], \"genres\": info['genres'], \n",
    "                        \"internal_id\": internal_id_int\n",
    "                    })\n",
    "                else:\n",
    "                     liked_movies_details.append({\n",
    "                        \"title\": f\"Unknown Liked Movie (Internal ID: {internal_id_int})\", \"genres\": \"N/A\",\n",
    "                        \"internal_id\": internal_id_int\n",
    "                    })\n",
    "        \n",
    "        return recommended_movies_details, liked_movies_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return [], []\n",
    "\n",
    "# --- Simulate a User and their History ---\n",
    "SIMULATED_USER_ID_STR = \"3\" \n",
    "SIMULATED_LIKED_MOVIE_ORIGINAL_IDS_STR = [\"50\", \"100\", \"181\"] \n",
    "\n",
    "recommendations = [] \n",
    "liked_movie_details_for_prompt = [] \n",
    "user_full_history_details = []\n",
    "\n",
    "if recbole_model and recbole_dataset and movie_info_map: \n",
    "    print(f\"\\n--- Full Positive Interaction History for User (Original ID: {SIMULATED_USER_ID_STR}) ---\")\n",
    "    user_full_history_details = get_user_history_details(recbole_dataset, SIMULATED_USER_ID_STR, movie_info_map)\n",
    "    if user_full_history_details:\n",
    "        for item in user_full_history_details[:10]: \n",
    "            print(f\"- {item['title']} (Genres: {item['genres']}, Rating: {item.get('rating', 'N/A')})\")\n",
    "        if len(user_full_history_details) > 10:\n",
    "            print(f\"  ... and {len(user_full_history_details) - 10} more items.\")\n",
    "    else:\n",
    "        print(\"No historical interactions found for this user or an error occurred.\")\n",
    "\n",
    "    recommendations, liked_movie_details_for_prompt = get_recommendations_for_user(\n",
    "        recbole_model, \n",
    "        recbole_dataset, \n",
    "        SIMULATED_USER_ID_STR, \n",
    "        SIMULATED_LIKED_MOVIE_ORIGINAL_IDS_STR, \n",
    "        NUM_RECOMMENDATIONS,\n",
    "        movie_info_map \n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Simulated User (Original ID: {SIMULATED_USER_ID_STR}) ---\")\n",
    "    print(\"Liked Movies (specifically for LLM prompt context):\") \n",
    "    if liked_movie_details_for_prompt:\n",
    "        for movie in liked_movie_details_for_prompt:\n",
    "            print(f\"- {movie['title']} (Genres: {movie['genres']})\")\n",
    "    else:\n",
    "        print(\"No specific 'liked movies for prompt' details to display.\")\n",
    "\n",
    "    print(\"\\nTop Recommendations (after filtering liked movies for prompt):\")\n",
    "    if recommendations:\n",
    "        for i, movie in enumerate(recommendations):\n",
    "            print(f\"{i+1}. {movie['title']} (Genres: {movie['genres']})\")\n",
    "    else:\n",
    "        print(\"No recommendations generated or an error occurred.\")\n",
    "elif not movie_info_map:\n",
    "    print(\"Movie info (from .item file) not loaded. Cannot proceed with user simulation and recommendations.\")\n",
    "else:\n",
    "    print(\"RecBole model/dataset not loaded. Skipping recommendation generation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full Positive Interaction History for User (Original ID: 3) ---\n",
      "- Natural Born Killers (Genres: Action Thriller, Rating: N/A)\n",
      "- Flipper (Genres: Adventure Children's, Rating: N/A)\n",
      "- Space Jam (Genres: Adventure Animation Children's Comedy Fantasy, Rating: N/A)\n",
      "- Evil Dead II (Genres: Action Adventure Comedy Horror, Rating: N/A)\n",
      "- Lost World: Jurassic Park, The (Genres: Action Adventure Sci-Fi Thriller, Rating: N/A)\n",
      "- Replacement Killers, The (Genres: Action Thriller, Rating: N/A)\n",
      "- Naked (Genres: Drama, Rating: N/A)\n",
      "- Father of the Bride (Genres: Comedy, Rating: N/A)\n",
      "- One Fine Day (Genres: Drama Romance, Rating: N/A)\n",
      "- Snow White and the Seven Dwarfs (Genres: Animation Children's Musical, Rating: N/A)\n",
      "  ... and 44 more items.\n",
      "\n",
      "--- Simulated User (Original ID: 3) ---\n",
      "Liked Movies (specifically for LLM prompt context):\n",
      "- Spawn (Genres: Action Adventure Sci-Fi Thriller)\n",
      "- Star Wars (Genres: Action Adventure Romance Sci-Fi War)\n",
      "- Natural Born Killers (Genres: Action Thriller)\n",
      "\n",
      "Top Recommendations (after filtering liked movies for prompt):\n",
      "1. GoldenEye (Genres: Action Adventure Thriller)\n",
      "2. Touch of Evil (Genres: Crime Film-Noir Thriller)\n",
      "3. Weekend at Bernie's (Genres: Comedy)\n",
      "4. East of Eden (Genres: Drama)\n",
      "5. Three Colors: White (Genres: Drama)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "6d879fc9b815c806",
   "metadata": {},
   "source": [
    "## 6. Conversational Agent with Gemini\n",
    "\n",
    "This section defines a function to interact with the Gemini API. It will take the user's request, the generated movie recommendations (with titles and genres), and the user's liked movies (with titles and genres) to craft a conversational response that includes explanations."
   ]
  },
  {
   "cell_type": "code",
   "id": "c12d21002c76bd6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:47.354040Z",
     "start_time": "2025-05-21T22:02:45.478072Z"
    }
   },
   "source": [
    "async def get_conversational_recommendation_with_explanation(user_query, recommended_movies, liked_movies_history):\n",
    "    if not SDK_CONFIGURED_SUCCESSFULLY:\n",
    "        return \"Sorry, I'm having trouble connecting to my brain right now. Please try again later.\"\n",
    "    if not recommended_movies:\n",
    "        return \"I couldn't find any specific recommendations for you right now, but I'm always learning! Perhaps try a broader query?\"\n",
    "\n",
    "    liked_movies_str = \"\"\n",
    "    if liked_movies_history:\n",
    "        liked_movies_parts = [f\"'{movie['title']}' (Genres: {movie['genres']})\" for movie in liked_movies_history]\n",
    "        if liked_movies_parts:\n",
    "            liked_movies_str = \"You previously liked: \" + \", \".join(liked_movies_parts) + \".\"\n",
    "\n",
    "    recs_str_parts = []\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        recs_str_parts.append(f\"{i+1}. '{movie['title']}' (Genres: {movie['genres']})\")\n",
    "    recs_str = \"\\n\".join(recs_str_parts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a friendly and helpful movie recommendation chatbot.\n",
    "    A user has asked: \"{user_query}\"\n",
    "    {liked_movies_str}\n",
    "\n",
    "    Here are some movie recommendations for the user:\n",
    "    {recs_str}\n",
    "\n",
    "    Your task is to:\n",
    "    1.  Present these recommendations in a conversational and engaging way.\n",
    "    2.  For each recommended movie, try to provide a brief, plausible explanation for why the user might like it, ideally by connecting it to their liked movies (considering titles and genres). For example, if they liked a sci-fi movie, and you recommend another sci-fi movie, mention that. If they liked a comedy, and you recommend another, highlight that.\n",
    "    3.  If you cannot find a strong direct link, provide a more general positive statement about the recommended movie.\n",
    "    4.  Keep the tone light and friendly. Do not invent movies or facts not provided.\n",
    "    5.  Structure your response as a single chat message.\n",
    "    \"\"\"\n",
    "\n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    "    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', safety_settings=safety_settings)\n",
    "    \n",
    "    try:\n",
    "        response = await model.generate_content_async(contents=[prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error interacting with Gemini API: {e}\")\n",
    "        return \"I'm sorry, I encountered an issue while trying to generate your recommendations with explanations. Please try again.\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "e61530a0bae1eff2",
   "metadata": {},
   "source": [
    "## 7. Showcase Chatbot Interaction\n",
    "\n",
    "Let's simulate a user asking for recommendations and see how our Gemini-powered chatbot responds, using the recommendations generated by the RecBole model.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2247d00beb160e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:02:59.516803Z",
     "start_time": "2025-05-21T22:02:47.356404Z"
    }
   },
   "source": [
    "async def run_chatbot_example():\n",
    "    if not recommendations : \n",
    "        print(\"No recommendations available to run the chatbot example.\")\n",
    "        print(\"This might be due to errors in loading the RecBole model or generating recommendations.\")\n",
    "        return\n",
    "    # No need to check liked_movie_details_for_prompt here, as the LLM prompt handles its absence\n",
    "\n",
    "    user_chat_query = \"Can you recommend some movies for me?\"\n",
    "    print(f\"\\nSimulated User Query: {user_chat_query}\")\n",
    "    \n",
    "    chatbot_response = await get_conversational_recommendation_with_explanation(\n",
    "        user_chat_query,\n",
    "        recommendations,\n",
    "        liked_movie_details_for_prompt \n",
    "    )\n",
    "    \n",
    "    print(\"\\nChatbot Response:\")\n",
    "    print(chatbot_response)\n",
    "\n",
    "if SDK_CONFIGURED_SUCCESSFULLY and recbole_model and recbole_dataset and movie_info_map and PROCESSED_ITEM_FILE_FOUND: # Changed U_ITEM_FOUND to PROCESSED_ITEM_FILE_FOUND\n",
    "    if recommendations: \n",
    "        await run_chatbot_example() \n",
    "    else:\n",
    "        print(\"\\nSkipping chatbot example because no recommendations were generated (check previous steps).\")\n",
    "else:\n",
    "    print(\"\\nSkipping chatbot example because prerequisites (SDK, model, data, processed .item file, or initial recommendations) are missing.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulated User Query: Can you recommend some movies for me?\n",
      "\n",
      "Chatbot Response:\n",
      "Hey there!  Looking for some movie magic, huh?  Based on your taste for action-packed adventures like *Spawn* and *Star Wars*, and the thrillers like *Natural Born Killers*, I've got a few suggestions that might tickle your fancy:\n",
      "\n",
      "1. **GoldenEye:** This one's a classic action-adventure thriller, similar in vein to *Spawn* and *Star Wars*.  It's got plenty of thrilling action sequences and a compelling plot that will keep you on the edge of your seat!\n",
      "\n",
      "2. **Touch of Evil:**  If you enjoy the darker, more suspenseful side of thrillers (like *Natural Born Killers*), you might really dig *Touch of Evil*. It's a classic film-noir thriller with a fantastically twisted plot and memorable performances.\n",
      "\n",
      "3. **Weekend at Bernie's:**  Need a break from all the action? This is a hilarious comedy that's perfect for a lighthearted watch. It's a totally different vibe, but sometimes a good laugh is exactly what you need!\n",
      "\n",
      "4. **East of Eden:** For something completely different, but still powerful, I recommend *East of Eden*.  It's a drama with compelling characters and a strong narrative. While it's not an action movie, it has the same sort of engaging storytelling that makes films like *Star Wars* so captivating.\n",
      "\n",
      "5. **Three Colors: White:** Another drama, but with a very different tone from *East of Eden*.  *Three Colors: White* is a critically acclaimed film with a unique style and thought-provoking themes. It might not be what you usually watch, but sometimes venturing outside your comfort zone leads to amazing discoveries!\n",
      "\n",
      "Let me know what you think!  Happy watching!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "b7580488a6410274",
   "metadata": {},
   "source": [
    "**Explanation Quality:**\n",
    "- The quality of explanations generated by the LLM heavily depends on:\n",
    "    - **Prompt Engineering:** How well the prompt guides the LLM to connect liked items with recommendations.\n",
    "    - **Available Information:** Providing genres (as we did) is helpful. More detailed item metadata (e.g., keywords, plot summaries, actors, directors) for both liked and recommended items would allow for richer and more accurate explanations.\n",
    "    - **LLM Capabilities:** The LLM's ability to infer relationships and articulate them naturally.\n",
    "- Simple genre-matching is a good starting point. More sophisticated explanations might require the LLM to understand deeper thematic connections or stylistic similarities.\n",
    "\n",
    "**Further Improvements:**\n",
    "1.  **Richer Item Metadata:** Incorporate more detailed movie metadata (plot keywords, director, main actors) into the prompt for both liked and recommended items to enable more nuanced explanations.\n",
    "2.  **User Feedback Loop:** In a real system, user feedback on recommendations and explanations could be used to fine-tune the LLM prompts or even the recommendation model.\n",
    "3.  **Multi-Turn Conversation:** Extend the chatbot to handle follow-up questions like \"Tell me more about 'Movie X'\" or \"Recommend something similar but less action-packed.\"\n",
    "4.  **Negative Feedback:** Allow users to say they disliked a recommendation, and use that to refine future suggestions and explanations.\n",
    "5.  **Diversity in Explanations:** Prompt the LLM to vary its explanation styles to avoid sounding repetitive.\n",
    "6.  **Knowledge Cutoff:** Be mindful of the LLM's knowledge cutoff if asking for information about very recent movies not in its training data (though here we provide the movie details directly).\n",
    "7.  **Fact-Checking (if LLM generates external info):** If the LLM were allowed to bring in external knowledge for explanations, a fact-checking layer might be needed. In our current setup, we are trying to constrain it to the provided data.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ee169e402b85ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:03:00.506631Z",
     "start_time": "2025-05-21T22:02:59.521062Z"
    }
   },
   "source": [
    "async def full_conversational_pipeline():\n",
    "    global movie_info_map, recbole_model, recbole_dataset, recommendations, liked_movie_details_for_prompt, PROCESSED_ITEM_FILE_FOUND, user_full_history_details\n",
    "\n",
    "    # Re-check PROCESSED_ITEM_FILE_FOUND at the start of the pipeline\n",
    "    item_file_check_path = os.path.join(ML_100K_PROCESSED_PATH, RECDOBOLE_ITEM_FILE_NAME)\n",
    "    PROCESSED_ITEM_FILE_FOUND = os.path.exists(item_file_check_path)\n",
    "    if not PROCESSED_ITEM_FILE_FOUND:\n",
    "        print(f\"CRITICAL (Pipeline Start): RecBole's processed item file not found at {item_file_check_path}. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Movie Info from RecBole's .item file\n",
    "    movie_info_map = load_recbole_item_data(RECDOBOLE_ITEM_FILE_PATH)\n",
    "    if not movie_info_map: return\n",
    "\n",
    "    # 2. Load RecBole Model\n",
    "    if MODEL_CHECKPOINT_PATH and os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "        try:\n",
    "            config, model, dataset, _, _, _ = load_data_and_model(model_file=MODEL_CHECKPOINT_PATH)\n",
    "            recbole_model = model\n",
    "            recbole_dataset = dataset\n",
    "            recbole_config = config # Store the loaded config\n",
    "            recbole_model.eval()\n",
    "            recbole_model.to(torch.device('cpu'))\n",
    "            print(f\"Successfully loaded model: {recbole_config['model']} on device: {next(recbole_model.parameters()).device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading RecBole model in full pipeline: {e}\")\n",
    "            recbole_model, recbole_dataset = None, None \n",
    "            return \n",
    "    else:\n",
    "        print(\"Model checkpoint path not valid in full pipeline. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # 3. Simulate User and Get Recommendations (also prints full history)\n",
    "    if recbole_model and recbole_dataset and movie_info_map:\n",
    "        # --- Fetch and print the user's actual historical positive interactions ---\n",
    "        print(f\"\\n--- Full Positive Interaction History for User (Original ID: {SIMULATED_USER_ID_STR}) ---\")\n",
    "        user_full_history_details = get_user_history_details(recbole_dataset, SIMULATED_USER_ID_STR, movie_info_map)\n",
    "        if user_full_history_details:\n",
    "            for item in user_full_history_details[:10]: # Print up to 10 historical items\n",
    "                print(f\"- {item['title']} (Genres: {item['genres']}, Rating: {item.get('rating', 'N/A')})\")\n",
    "            if len(user_full_history_details) > 10:\n",
    "                print(f\"  ... and {len(user_full_history_details) - 10} more items.\")\n",
    "        else:\n",
    "            print(\"No historical interactions found for this user or an error occurred.\")\n",
    "\n",
    "        # --- Get recommendations (this also prepares liked_movie_details_for_prompt) ---\n",
    "        recommendations, liked_movie_details_for_prompt = get_recommendations_for_user(\n",
    "            recbole_model, \n",
    "            recbole_dataset, \n",
    "            SIMULATED_USER_ID_STR, \n",
    "            SIMULATED_LIKED_MOVIE_ORIGINAL_IDS_STR, \n",
    "            NUM_RECOMMENDATIONS,\n",
    "            movie_info_map\n",
    "        )\n",
    "        print(f\"\\n--- Simulated User (Original ID: {SIMULATED_USER_ID_STR}) (Full Pipeline) ---\")\n",
    "        print(\"Liked Movies (specifically for LLM prompt context):\")\n",
    "        if liked_movie_details_for_prompt: \n",
    "            for movie in liked_movie_details_for_prompt: print(f\"- {movie['title']} (Genres: {movie['genres']})\")\n",
    "        else:\n",
    "            print(\"No liked movie details to display for prompt context.\")\n",
    "\n",
    "        print(\"\\nTop Recommendations (after filtering liked movies for prompt):\")\n",
    "        if recommendations:\n",
    "            for i, movie in enumerate(recommendations): print(f\"{i+1}. {movie['title']} (Genres: {movie['genres']})\")\n",
    "        else:\n",
    "            print(\"No recommendations generated in full pipeline.\")\n",
    "    else:\n",
    "        print(\"Skipping recommendation generation in full pipeline due to missing components.\")\n",
    "        recommendations = [] \n",
    "        liked_movie_details_for_prompt = []\n",
    "        user_full_history_details = []\n",
    "\n",
    "\n",
    "    # 4. Run Chatbot Example\n",
    "    if SDK_CONFIGURED_SUCCESSFULLY and recommendations: \n",
    "        await run_chatbot_example()\n",
    "    else:\n",
    "        print(\"\\nSkipping chatbot example in full pipeline due to missing SDK config or recommendations.\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "1b83836a793c4147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:03:08.026965Z",
     "start_time": "2025-05-21T22:03:00.508423Z"
    }
   },
   "source": [
    "await full_conversational_pipeline()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded information for 1682 movies from RecBole's .item file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tduricic/anaconda3/envs/llm-eval/lib/python3.10/site-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_file)\n",
      "22 May 00:03    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = -1\n",
      "use_gpu = True\n",
      "seed = 2024\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /home/tduricic/anaconda3/envs/llm-eval/lib/python3.10/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = /mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'Precision', 'NDCG', 'MRR', 'ItemCoverage', 'GiniIndex', 'ShannonEntropy', 'AveragePopularity', 'TailPercentage']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 2048\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 3}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "n_layers = 2\n",
      "reg_weight = 1e-05\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "reproducible = True\n",
      "download_original_data = True\n",
      "eval_setting = RO_RS,full\n",
      "split_ratio = [0.8, 0.1, 0.1]\n",
      "leave_one_out = False\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "22 May 00:03    INFO  Load filtered dataset from: [/mnt/c/Users/tduricic/Development/workspace/conversational-reco/recbole_saved_models/ml-100k/LightGCN_20250521_203428/ml-100k-Dataset.pth]\n",
      "22 May 00:03    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'label']\n",
      "22 May 00:03    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "22 May 00:03    INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model: LightGCN on device: cpu\n",
      "\n",
      "--- Full Positive Interaction History for User (Original ID: 3) ---\n",
      "- Natural Born Killers (Genres: Action Thriller, Rating: N/A)\n",
      "- Flipper (Genres: Adventure Children's, Rating: N/A)\n",
      "- Space Jam (Genres: Adventure Animation Children's Comedy Fantasy, Rating: N/A)\n",
      "- Evil Dead II (Genres: Action Adventure Comedy Horror, Rating: N/A)\n",
      "- Lost World: Jurassic Park, The (Genres: Action Adventure Sci-Fi Thriller, Rating: N/A)\n",
      "- Replacement Killers, The (Genres: Action Thriller, Rating: N/A)\n",
      "- Naked (Genres: Drama, Rating: N/A)\n",
      "- Father of the Bride (Genres: Comedy, Rating: N/A)\n",
      "- One Fine Day (Genres: Drama Romance, Rating: N/A)\n",
      "- Snow White and the Seven Dwarfs (Genres: Animation Children's Musical, Rating: N/A)\n",
      "  ... and 44 more items.\n",
      "\n",
      "--- Simulated User (Original ID: 3) (Full Pipeline) ---\n",
      "Liked Movies (specifically for LLM prompt context):\n",
      "- Spawn (Genres: Action Adventure Sci-Fi Thriller)\n",
      "- Star Wars (Genres: Action Adventure Romance Sci-Fi War)\n",
      "- Natural Born Killers (Genres: Action Thriller)\n",
      "\n",
      "Top Recommendations (after filtering liked movies for prompt):\n",
      "1. GoldenEye (Genres: Action Adventure Thriller)\n",
      "2. Touch of Evil (Genres: Crime Film-Noir Thriller)\n",
      "3. Weekend at Bernie's (Genres: Comedy)\n",
      "4. East of Eden (Genres: Drama)\n",
      "5. Three Colors: White (Genres: Drama)\n",
      "\n",
      "Simulated User Query: Can you recommend some movies for me?\n",
      "\n",
      "Chatbot Response:\n",
      "Hey there!  So you're looking for some movie recommendations?  Awesome! Based on your taste for action-packed flicks like *Spawn* and *Star Wars*, and even the thrilling ride that is *Natural Born Killers*, I've got a few suggestions that might tickle your fancy:\n",
      "\n",
      "1. **GoldenEye:** This one's a real blast!  If you enjoyed the action and adventure in *Spawn* and *Star Wars*, you'll definitely appreciate the thrills and spills in *GoldenEye*. It's got plenty of action sequences and a gripping storyline.\n",
      "\n",
      "2. **Touch of Evil:**  Okay, this one's a bit of a different vibe, more of a classic thriller with a strong crime element.  While it doesn't share the sci-fi elements of your previous favorites, it has the same edge-of-your-seat suspense that you probably loved in *Natural Born Killers*. It's a film-noir masterpiece, too, if you're into that kind of atmosphere!\n",
      "\n",
      "3. **Weekend at Bernie's:**  Time for something completely different!  This is a hilarious comedy, a total change of pace if youre looking for a lighter watch.  Its pure, unadulterated fun.\n",
      "\n",
      "4. **East of Eden:**  If you're up for something a little more dramatic, *East of Eden* is a powerful and moving story. It's a classic drama that's really well-made, and it might appeal to you if you appreciate strong narratives.\n",
      "\n",
      "5. **Three Colors: White:** Another drama, this one's a bit more art-house and thought-provoking.  It's a beautifully made film, and although it's quite different from the action movies you've mentioned, it still has a compelling narrative and strong characters that I think you'll appreciate.\n",
      "\n",
      "\n",
      "Let me know what you think!  I'm happy to offer more suggestions if these don't quite hit the mark.  Happy watching!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "f633692236b551bb",
   "metadata": {},
   "source": [
    "## 9. Interactive Chat Widget\n",
    "\n",
    "This section provides an interactive chat interface using `ipywidgets`. You can type in a movie recommendation request, and the chatbot (powered by Gemini and using the loaded RecBole model's recommendations) will respond.\n",
    "\n",
    "**Note:**\n",
    "- Ensure the previous cells (especially model loading and initial recommendation generation for the simulated user) have been run successfully in the current session. The chatbot uses the globally available `recommendations` and `liked_movie_details_for_prompt` variables for context.\n",
    "- The first interaction with the widget will use the recommendations generated for `SIMULATED_USER_ID_STR`. Subsequent queries in the widget will reuse this initial recommendation context for the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d7fb577fc4fa5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:03:08.916988Z",
     "start_time": "2025-05-21T22:03:08.029163Z"
    }
   },
   "source": [
    "# Global list to store chat messages for display\n",
    "chat_history_display = []\n",
    "\n",
    "# Output widget to display the chat\n",
    "chat_output = widgets.Output(layout={'border': '1px solid black', 'height': '300px', 'overflow_y': 'auto', 'padding': '10px'})\n",
    "\n",
    "# Text input for user\n",
    "user_input_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Ask for movie recommendations...',\n",
    "    description='You:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Button to send message\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='success', \n",
    "    tooltip='Send your message',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "\n",
    "async def display_chat_message(sender, message_text):\n",
    "    \"\"\"Appends and displays a message in the chat_output widget, rendering Markdown.\"\"\"\n",
    "    chat_history_display.append(f\"**{sender}:** {message_text}\\n\")\n",
    "    with chat_output:\n",
    "        clear_output(wait=True) # Clear previous output before re-rendering\n",
    "        for msg in chat_history_display:\n",
    "            display(Markdown(msg)) # Render each message as Markdown\n",
    "\n",
    "async def on_send_button_clicked(b):\n",
    "    \"\"\"Handles the send button click event.\"\"\"\n",
    "    user_query = user_input_widget.value\n",
    "    if not user_query.strip():\n",
    "        return\n",
    "\n",
    "    await display_chat_message(\"You\", user_query)\n",
    "    user_input_widget.value = '' # Clear input field\n",
    "\n",
    "    # Show thinking indicator\n",
    "    await display_chat_message(\"Chatbot\", \"_Thinking..._\")\n",
    "\n",
    "    # Use the globally available recommendations and liked_movies_for_prompt\n",
    "    # These should have been populated by running earlier cells (e.g., CELL 10 or full_conversational_pipeline)\n",
    "    if 'recommendations' not in globals() or 'liked_movie_details_for_prompt' not in globals():\n",
    "        await display_chat_message(\"Chatbot\", \"Sorry, the recommendation context is not set up. Please run the data loading and recommendation cells first.\")\n",
    "        return\n",
    "\n",
    "    # If recommendations list is empty, it means initial rec generation failed or user has no recs\n",
    "    if not recommendations:\n",
    "         await display_chat_message(\"Chatbot\", \"I don't have specific recommendations based on the initial context. Can you tell me about some movies you like?\")\n",
    "         return\n",
    "\n",
    "    chatbot_response_text = await get_conversational_recommendation_with_explanation(\n",
    "        user_query,\n",
    "        recommendations, # Use the pre-generated recommendations for SIMULATED_USER_ID\n",
    "        liked_movie_details_for_prompt # Use the liked movies of SIMULATED_USER_ID for context\n",
    "    )\n",
    "    \n",
    "    # Remove the \"Thinking...\" message and add the actual response\n",
    "    if chat_history_display and chat_history_display[-1].endswith(\"_Thinking..._\\n\"):\n",
    "        chat_history_display.pop()\n",
    "    \n",
    "    await display_chat_message(\"Chatbot\", chatbot_response_text)\n",
    "\n",
    "send_button.on_click(lambda b: asyncio.ensure_future(on_send_button_clicked(b)))\n",
    "\n",
    "# Display the chat interface\n",
    "# Ensure previous cells (model loading, initial recommendation) have run to populate 'recommendations'\n",
    "# and 'liked_movie_details_for_prompt'\n",
    "if 'recommendations' in globals() and 'liked_movie_details_for_prompt' in globals():\n",
    "    print(\"Interactive chat widget ready. Type your query below and press Send.\")\n",
    "    # Initial message from chatbot (optional)\n",
    "    # asyncio.ensure_future(display_chat_message(\"Chatbot\", \"Hello! How can I help you with movie recommendations today? The current context is based on a simulated user.\"))\n",
    "    display(widgets.VBox([chat_output, widgets.HBox([user_input_widget, send_button])]))\n",
    "else:\n",
    "    print(\"Please run the cells above to load the model and generate initial recommendations before using the chat widget.\")\n",
    "    print(\"(Specifically, ensure 'recommendations' and 'liked_movie_details_for_prompt' are populated).\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive chat widget ready. Type your query below and press Send.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_rig"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd832b31ea5147b2b0b35ef903a2d4c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "beb2435368d597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T22:03:09.907007Z",
     "start_time": "2025-05-21T22:03:08.918886Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
